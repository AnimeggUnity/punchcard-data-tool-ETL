"""
ETL ç®¡é“ - æ•´åˆè³‡æ–™è®€å–ã€é©—è­‰ã€è½‰æ›å’Œè¼‰å…¥
"""

from typing import List, Callable, Optional, Dict, Any
import pandas as pd
import sqlite3
from pathlib import Path
import logging
from datetime import datetime

from .models import PunchRecord, ShiftClass, ValidationResult
from .readers import DataReader
from .validators import DataValidator

logger = logging.getLogger(__name__)


class ETLPipeline:
    """é€šç”¨ ETL ç®¡é“"""
    
    def __init__(self, reader: DataReader, validator: Optional[DataValidator] = None,
                 output_callback: Callable = None):
        self.reader = reader
        self.validator = validator
        self.output_callback = output_callback or (lambda x: logger.info(x))
        
        self.extracted_data: Optional[pd.DataFrame] = None
        self.valid_records: List = []
        self.validation_result: Optional[ValidationResult] = None
    
    def extract(self) -> pd.DataFrame:
        self.output_callback("=" * 50)
        self.output_callback("éšæ®µ 1: æå–è³‡æ–™")
        self.output_callback("=" * 50)
        self.extracted_data = self.reader.read()
        self.output_callback(f"æå–å®Œæˆï¼Œå…± {len(self.extracted_data)} ç­†")
        return self.extracted_data

    def transform(self, df: pd.DataFrame = None, column_mapping: Dict[str, str] = None) -> pd.DataFrame:
        """
        è½‰æ›è³‡æ–™ï¼ˆåŒ…å«æ¬„ä½æ¨™æº–åŒ–ï¼‰

        Args:
            df: è¦è½‰æ›çš„ DataFrameï¼ˆè‹¥ç‚º None å‰‡ä½¿ç”¨ extracted_dataï¼‰
            column_mapping: æ¬„ä½åç¨±å°ç…§è¡¨ï¼ˆä¾‹å¦‚ ColumnNaming.PUNCH_COLUMNSï¼‰

        Returns:
            è½‰æ›å¾Œçš„ DataFrame
        """
        df = df if df is not None else self.extracted_data
        if df is None:
            raise ValueError("å°šæœªæå–è³‡æ–™")

        if column_mapping:
            self.output_callback("ğŸ”„ è½‰æ›æ¬„ä½åç¨±...")
            # åªè½‰æ›å­˜åœ¨çš„æ¬„ä½
            existing_mapping = {k: v for k, v in column_mapping.items() if k in df.columns}
            df = df.rename(columns=existing_mapping)
            self.output_callback(f"   âœ“ å·²æ¨™æº–åŒ– {len(existing_mapping)} å€‹æ¬„ä½")
            self.output_callback(f"   æ¨™æº–æ¬„ä½: {list(df.columns)[:8]}...")

        return df

    def validate(self, df: pd.DataFrame = None) -> tuple:
        self.output_callback("=" * 50)
        self.output_callback("éšæ®µ 2: é©—è­‰è³‡æ–™")
        self.output_callback("=" * 50)
        
        df = df if df is not None else self.extracted_data
        if df is None:
            raise ValueError("å°šæœªæå–è³‡æ–™")
        
        if self.validator is None:
            self.valid_records = df.to_dict('records')
            self.validation_result = ValidationResult(success=True, valid_count=len(df))
        else:
            self.valid_records, self.validation_result = self.validator.validate(df, self.output_callback)
        
        return self.valid_records, self.validation_result
    
    def load_to_sqlite(self, db_path: str, table_name: str, if_exists: str = 'replace') -> int:
        self.output_callback("=" * 50)
        self.output_callback("éšæ®µ 3: è¼‰å…¥è³‡æ–™")
        self.output_callback("=" * 50)
        
        if not self.valid_records:
            self.output_callback("æ²’æœ‰è³‡æ–™å¯è¼‰å…¥")
            return 0
        
        Path(db_path).parent.mkdir(parents=True, exist_ok=True)
        
        df = pd.DataFrame([
            r.model_dump() if hasattr(r, 'model_dump') else r
            for r in self.valid_records
        ])
        
        conn = sqlite3.connect(db_path)
        df.to_sql(table_name, conn, if_exists=if_exists, index=False)
        conn.close()
        
        self.output_callback(f"è¼‰å…¥å®Œæˆï¼Œ{len(df)} ç­†è‡³ {table_name}")
        return len(df)
    
    def execute(self, db_path: str, table_name: str, if_exists: str = 'replace') -> Dict[str, Any]:
        start = datetime.now()
        try:
            self.extract()
            self.validate()
            loaded = self.load_to_sqlite(db_path, table_name, if_exists)
            duration = (datetime.now() - start).total_seconds()
            
            self.output_callback("=" * 50)
            self.output_callback(f"ETL å®Œæˆï¼Œè€—æ™‚ {duration:.2f} ç§’")
            
            return {
                'success': True,
                'extracted': len(self.extracted_data) if self.extracted_data is not None else 0,
                'valid': len(self.valid_records),
                'errors': self.validation_result.error_count if self.validation_result else 0,
                'loaded': loaded,
                'duration': duration
            }
        except Exception as e:
            self.output_callback(f"ETL å¤±æ•—: {e}")
            return {'success': False, 'error': str(e)}


class PunchDataETL:
    """æ‰“å¡è³‡æ–™å°ˆç”¨ ETL - æ­£ç¢ºçš„ Extract â†’ Transform â†’ Validate â†’ Load æµç¨‹"""

    def __init__(self, punch_reader: DataReader, shift_reader: DataReader,
                 driver_reader: Optional[DataReader] = None, output_callback: Callable = None):
        self.punch_reader = punch_reader
        self.shift_reader = shift_reader
        self.driver_reader = driver_reader
        self.output_callback = output_callback or (lambda x: logger.info(x))
    
    def execute(self, db_path: str) -> Dict[str, Any]:
        self.output_callback("é–‹å§‹è™•ç†æ‰“å¡è³‡æ–™...")
        start = datetime.now()
        
        try:
            Path(db_path).parent.mkdir(parents=True, exist_ok=True)
            
            # === è™•ç†æ‰“å¡è³‡æ–™ï¼ˆèˆ‡ main_app.py ç›¸åŒé‚è¼¯ï¼‰===
            self.output_callback("=" * 50)
            self.output_callback("è™•ç†æ‰“å¡è³‡æ–™")
            self.output_callback("=" * 50)
            
            punch_df = self._read_punch_data()
            if punch_df.empty:
                return {'success': False, 'error': 'æ²’æœ‰æ‰“å¡è³‡æ–™'}
            
            self.output_callback(f"æ¬„ä½: {list(punch_df.columns)}")
            self.output_callback(f"å‰3ç­†è³‡æ–™ç¯„ä¾‹:")
            for i, row in punch_df.head(3).iterrows():
                self.output_callback(f"  {i}: å¸³è™Ÿ={row.get('å…¬å‹™å¸³è™Ÿ', 'N/A')}, æ—¥æœŸ={row.get('åˆ·å¡æ—¥æœŸ', 'N/A')}, æ™‚é–“={row.get('åˆ·å¡æ™‚é–“', 'N/A')}")
            
            # è½‰æ›æ ¼å¼
            punch_df = self._transform_punch_data(punch_df)

            # æ¬„ä½æ¨™æº–åŒ–
            from config import ColumnNaming
            punch_df = punch_df.rename(columns=ColumnNaming.PUNCH_COLUMNS)
            self.output_callback(f"âœ“ æ¬„ä½å·²æ¨™æº–åŒ–: {list(punch_df.columns)[:8]}...")

            # Pydantic é©—è­‰ï¼ˆä½¿ç”¨æ¨™æº–åŒ–æ¬„ä½ï¼‰
            valid_punch = []  # åˆå§‹åŒ–ç‚ºç©ºåˆ—è¡¨
            try:
                punch_validator = DataValidator(PunchRecord)
                valid_punch, punch_result = punch_validator.validate(punch_df, self.output_callback)
                self.output_callback(f"âœ… Pydantic é©—è­‰: {punch_result.valid_count} æˆåŠŸ, {punch_result.error_count} å¤±æ•—")
                if punch_result.error_count > 0:
                    self.output_callback(punch_result.get_error_summary(max_errors=5))
            except Exception as ve:
                self.output_callback(f"âš ï¸  Pydantic é©—è­‰è·³é: {ve}")
                # ç¢ºä¿åœ¨é©—è­‰å‡ºéŒ¯æ™‚ valid_punch è‚¯å®šæ˜¯ç©ºçš„
                valid_punch = []
            
            # è¼‰å…¥é€šéé©—è­‰çš„è³‡æ–™
            if valid_punch:
                validated_df = pd.DataFrame([r.model_dump() for r in valid_punch])
                conn = sqlite3.connect(db_path)
                validated_df.to_sql('punch', conn, if_exists='replace', index=False)
                conn.close()
                punch_loaded = len(validated_df)
                self.output_callback(f"è¼‰å…¥å®Œæˆï¼Œ{punch_loaded} ç­†æœ‰æ•ˆè³‡æ–™è‡³ punch")
            else:
                punch_loaded = 0
                self.output_callback("è­¦å‘Šï¼šæ²’æœ‰è³‡æ–™é€šéé©—è­‰ï¼Œæœªè¼‰å…¥ punch è³‡æ–™è¡¨ã€‚")
            
            # === è™•ç†ç­åˆ¥è³‡æ–™ ===
            self.output_callback("=" * 50)
            self.output_callback("è™•ç†ç­åˆ¥è³‡æ–™")
            self.output_callback("=" * 50)
            
            shift_df = self.shift_reader.read()
            self.output_callback(f"æ¬„ä½: {list(shift_df.columns)}")

            # æ¬„ä½æ¨™æº–åŒ–
            shift_df = shift_df.rename(columns=ColumnNaming.SHIFT_COLUMNS)
            self.output_callback(f"âœ“ æ¬„ä½å·²æ¨™æº–åŒ–: {list(shift_df.columns)}")

            conn = sqlite3.connect(db_path)
            shift_df.to_sql('shift_class', conn, if_exists='replace', index=False)
            conn.close()
            shift_loaded = len(shift_df)
            self.output_callback(f"è¼‰å…¥å®Œæˆï¼Œ{shift_loaded} ç­†è‡³ shift_class")

            # === è™•ç†å¸æ©Ÿåå–® ===
            driver_loaded = 0
            if self.driver_reader:
                self.output_callback("=" * 50)
                self.output_callback("è™•ç†å¸æ©Ÿåå–®")
                self.output_callback("=" * 50)

                driver_df = self.driver_reader.read()
                self.output_callback(f"æ¬„ä½: {list(driver_df.columns)}")

                # æ¬„ä½æ¨™æº–åŒ–
                driver_df = driver_df.rename(columns=ColumnNaming.DRIVER_COLUMNS)
                self.output_callback(f"âœ“ æ¬„ä½å·²æ¨™æº–åŒ–: {list(driver_df.columns)}")

                # æ¨™è¨˜ç‚ºå¸æ©Ÿ
                driver_df['is_driver'] = True

                conn = sqlite3.connect(db_path)
                driver_df.to_sql('driver_list', conn, if_exists='replace', index=False)
                conn.close()
                driver_loaded = len(driver_df)
                self.output_callback(f"è¼‰å…¥å®Œæˆï¼Œ{driver_loaded} ç­†è‡³ driver_list")

            # === æ•´åˆè³‡æ–™ ===
            integrated = self._integrate_data(db_path)
            
            duration = (datetime.now() - start).total_seconds()
            self.output_callback("=" * 50)
            self.output_callback(f"ETL å®Œæˆï¼Œè€—æ™‚ {duration:.2f} ç§’")
            
            return {
                'success': True,
                'punch_records': punch_loaded,
                'shift_records': shift_loaded,
                'driver_records': driver_loaded,
                'integrated_records': integrated,
                'total_duration': duration
            }
        except Exception as e:
            import traceback
            self.output_callback(f"è™•ç†å¤±æ•—: {traceback.format_exc()}")
            return {'success': False, 'error': str(e)}
    
    def _read_punch_data(self) -> pd.DataFrame:
        """
        è®€å–æ‰“å¡è³‡æ–™ - ä½¿ç”¨ ExcelReadingConfig è¨­å®š
        
        æœªä¾†æ ¼å¼è®Šæ›´åªéœ€ä¿®æ”¹ config.py ä¸­çš„ ExcelReadingConfig.PUNCH_DATA
        """
        from config import ExcelReadingConfig
        config = ExcelReadingConfig.PUNCH_DATA
        
        source_info = self.punch_reader.get_source_info()
        file_path = source_info.get('file', '')
        
        self.output_callback(f"è®€å–æ‰“å¡è³‡æ–™: {file_path}")
        self.output_callback(f"è¨­å®š: skip_rows={config['skip_rows']}, filter={config['filter_column']}")
        excel_file = pd.ExcelFile(file_path)
        
        dfs = []
        for sheet_name in excel_file.sheet_names:
            self.output_callback(f"  è™•ç†å·¥ä½œè¡¨: {sheet_name}")
            
            # ä½¿ç”¨è¨­å®šæª”çš„ skip_rows å’Œ header_row
            df = pd.read_excel(
                excel_file, 
                sheet_name=sheet_name, 
                skiprows=config['skip_rows'], 
                header=config['header_row']
            )
            
            # ç§»é™¤ç©ºç™½æ¬„ä½
            if config.get('remove_unnamed_columns', True):
                df = df.loc[:, ~df.columns.str.contains('^Unnamed', na=False)]
                df = df.loc[:, df.columns.notna()]
            
            self.output_callback(f"    è®€å–å¾Œæ¬„ä½: {list(df.columns)[:6]}")
            
            if df.empty:
                continue
            
            # ä½¿ç”¨è¨­å®šæª”çš„éæ¿¾æ¬„ä½
            filter_col = config.get('filter_column')
            if filter_col and filter_col in df.columns:
                before_count = len(df)
                df = df[pd.to_numeric(df[filter_col], errors='coerce').notnull()]
                after_count = len(df)
                self.output_callback(f"    {filter_col}éæ¿¾: {before_count} -> {after_count} ç­†")
            
            # æ¬„ä½é‡æ–°å‘½åï¼ˆå¦‚æœæœ‰è¨­å®šï¼‰
            column_mapping = config.get('column_mapping', {})
            if column_mapping:
                df = df.rename(columns=column_mapping)
            
            df = df.dropna(axis=1, how='all')
            
            # ç¢ºä¿æŒ‡å®šæ¬„ä½ç‚ºå­—ä¸²
            for col in config.get('string_columns', []):
                if col in df.columns:
                    df[col] = df[col].astype(str)
            
            if not df.empty:
                dfs.append(df)
                self.output_callback(f"    {sheet_name}: {len(df)} ç­†æœ‰æ•ˆè³‡æ–™")
        
        result = pd.concat(dfs, ignore_index=True) if dfs else pd.DataFrame()
        self.output_callback(f"å…±è®€å– {len(result)} ç­†æ‰“å¡è³‡æ–™")
        return result
    
    def _transform_punch_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """è½‰æ›æ‰“å¡è³‡æ–™æ ¼å¼ - åœ¨é©—è­‰å‰é€²è¡Œ"""
        self.output_callback("è½‰æ›æ—¥æœŸæ™‚é–“æ ¼å¼...")
        
        df = df.copy()
        
        # è½‰æ›æ—¥æœŸï¼šæ°‘åœ‹å¹´ (YYYMMDD) â†’ è¥¿å…ƒå¹´ (YYYY-MM-DD)
        if 'åˆ·å¡æ—¥æœŸ' in df.columns:
            def convert_date(val):
                if pd.isna(val):
                    return val
                val = str(val).strip()
                if len(val) == 7 and val.isdigit():
                    year = int(val[:3]) + 1911
                    return f"{year}-{val[3:5]}-{val[5:7]}"
                return val
            df['åˆ·å¡æ—¥æœŸ'] = df['åˆ·å¡æ—¥æœŸ'].apply(convert_date)
        
        # è½‰æ›æ™‚é–“ï¼šHHMMSS â†’ HH:MM:SS
        if 'åˆ·å¡æ™‚é–“' in df.columns:
            def convert_time(val):
                if pd.isna(val):
                    return val
                val = str(val).strip()
                # åªè™•ç† HHMMSS æ ¼å¼
                if len(val) == 6 and val.isdigit():
                    return f"{val[:2]}:{val[2:4]}:{val[4:6]}"
                # å¦‚æœæ ¼å¼ä¸ç¬¦ï¼Œå›å‚³åŸå§‹å€¼ä»¥ä¾¿æ–¼é™¤éŒ¯
                return val
            df['åˆ·å¡æ™‚é–“'] = df['åˆ·å¡æ™‚é–“'].apply(convert_time)
        
        self.output_callback("æ ¼å¼è½‰æ›å®Œæˆ")
        return df
    
    def _load_records(self, records: List, db_path: str, table_name: str, if_exists: str) -> int:
        """è¼‰å…¥è¨˜éŒ„åˆ°è³‡æ–™åº«"""
        if not records:
            self.output_callback(f"æ²’æœ‰è³‡æ–™å¯è¼‰å…¥åˆ° {table_name}")
            return 0
        
        df = pd.DataFrame([
            r.model_dump() if hasattr(r, 'model_dump') else r
            for r in records
        ])
        
        conn = sqlite3.connect(db_path)
        df.to_sql(table_name, conn, if_exists=if_exists, index=False)
        conn.close()
        
        self.output_callback(f"è¼‰å…¥å®Œæˆï¼Œ{len(df)} ç­†è‡³ {table_name}")
        return len(df)
    
    def _integrate_data(self, db_path: str) -> int:
        """æ•´åˆæ‰“å¡èˆ‡ç­åˆ¥è³‡æ–™"""
        self.output_callback("æ•´åˆæ‰“å¡èˆ‡ç­åˆ¥è³‡æ–™...")

        conn = sqlite3.connect(db_path)
        query = """
            SELECT p.account_id, s.emp_id, s.name, s.shift_class, p.punch_date,
                   GROUP_CONCAT(p.punch_time) AS time_list
            FROM punch p
            LEFT JOIN shift_class s ON p.account_id = s.account_id
            GROUP BY p.account_id, p.punch_date, s.shift_class
            ORDER BY p.account_id, p.punch_date
        """
        df = pd.read_sql_query(query, conn)

        # åˆ†å‰²æ™‚é–“
        if not df.empty and 'time_list' in df.columns:
            split_times = df['time_list'].str.split(',', expand=True)
            if split_times.shape[1] > 0:
                time_cols = [f'punch_time_{i+1}' for i in range(split_times.shape[1])]
                new_cols = pd.DataFrame(split_times.values, columns=time_cols).dropna(axis=1, how='all')
                df = pd.concat([df.drop(columns=['time_list']), new_cols], axis=1)
        
        df.to_sql('integrated_punch', conn, if_exists='replace', index=False)
        conn.close()
        
        self.output_callback(f"æ•´åˆå®Œæˆï¼Œ{len(df)} ç­†")
        return len(df)


